{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9682f523",
   "metadata": {},
   "source": [
    "<h1 style=\"color: green;\">Regression modelling Home Shopping Expenditure per week</h1>\n",
    "<p>\n",
    "The following tasks are accomplished in this section:\n",
    "<ul>\n",
    "<li>Hyperparameter tuning with GridSearchCV</li>\n",
    "<li>Retrieving the best parameters for the top 4 models from GridSearchCV</li>\n",
    "<li>Comparing VotingRegressor with the best model using cross validation</li>\n",
    "<li>Working with the best model</li>\n",
    "<li>Feature importance of the best model</li>\n",
    "<li>Exporting the best model for evaluation</li>\n",
    "</ul>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8c60e",
   "metadata": {},
   "source": [
    "<h1 style=\"color: green;\">Import libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d646b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as rf_r\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gb_r\n",
    "from sklearn.ensemble import AdaBoostRegressor as adb_r\n",
    "from xgboost import XGBRegressor as xgb_r\n",
    "from catboost import CatBoostRegressor as catb_r\n",
    "from lightgbm import LGBMRegressor as lgbm_r\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor as vot_r\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecf5a2",
   "metadata": {},
   "source": [
    "<h1 style=\"color: green;\">Load the data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7350f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../2. Data/homeshopping_Regressor_X_train.csv\")\n",
    "X_test = pd.read_csv(\"../2. Data/homeshopping_Regressor_X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115f3116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Nbr_of_Items</th>\n",
       "      <th>Total_Price</th>\n",
       "      <th>Date_diff</th>\n",
       "      <th>Nbr_trips_per_wk</th>\n",
       "      <th>Nbr_items_per_wk</th>\n",
       "      <th>Total_Exp_wk_perc</th>\n",
       "      <th>hour</th>\n",
       "      <th>Bread_wk</th>\n",
       "      <th>Bread_exp_wk</th>\n",
       "      <th>Bread_wk_exp_perc</th>\n",
       "      <th>...</th>\n",
       "      <th>Week_day_name_Monday</th>\n",
       "      <th>Week_day_name_Saturday</th>\n",
       "      <th>Week_day_name_Sunday</th>\n",
       "      <th>Week_day_name_Thursday</th>\n",
       "      <th>Week_day_name_Tuesday</th>\n",
       "      <th>Week_day_name_Wednesday</th>\n",
       "      <th>Part_of_day_Afternoon</th>\n",
       "      <th>Part_of_day_Evening</th>\n",
       "      <th>Part_of_day_Morning</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.086329</td>\n",
       "      <td>-0.236649</td>\n",
       "      <td>0.487672</td>\n",
       "      <td>-0.520909</td>\n",
       "      <td>-0.295981</td>\n",
       "      <td>-0.410729</td>\n",
       "      <td>-1.324821</td>\n",
       "      <td>2.398472</td>\n",
       "      <td>1.694186</td>\n",
       "      <td>0.381548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>-0.326219</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>2.680951</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>-0.974374</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>1.445553</td>\n",
       "      <td>-0.294171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.816953</td>\n",
       "      <td>-0.320357</td>\n",
       "      <td>-0.516810</td>\n",
       "      <td>2.902459</td>\n",
       "      <td>0.983922</td>\n",
       "      <td>-0.972653</td>\n",
       "      <td>0.450253</td>\n",
       "      <td>0.566403</td>\n",
       "      <td>-0.473094</td>\n",
       "      <td>-0.494051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>3.065424</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "      <td>0.181543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.170267</td>\n",
       "      <td>-0.134987</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>-1.376752</td>\n",
       "      <td>-1.350020</td>\n",
       "      <td>0.465925</td>\n",
       "      <td>-0.310493</td>\n",
       "      <td>-0.349632</td>\n",
       "      <td>0.511028</td>\n",
       "      <td>3.008344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>-0.326219</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>2.342039</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "      <td>-0.330668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.455640</td>\n",
       "      <td>-0.307790</td>\n",
       "      <td>-0.181982</td>\n",
       "      <td>0.334933</td>\n",
       "      <td>0.758057</td>\n",
       "      <td>-0.974993</td>\n",
       "      <td>0.450253</td>\n",
       "      <td>0.566403</td>\n",
       "      <td>-0.473094</td>\n",
       "      <td>-0.494051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>3.065424</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "      <td>0.582345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.274984</td>\n",
       "      <td>-0.184135</td>\n",
       "      <td>-0.516810</td>\n",
       "      <td>-0.806190</td>\n",
       "      <td>0.231038</td>\n",
       "      <td>-0.460624</td>\n",
       "      <td>0.703836</td>\n",
       "      <td>0.566403</td>\n",
       "      <td>-0.473094</td>\n",
       "      <td>-0.494051</td>\n",
       "      <td>...</td>\n",
       "      <td>2.225881</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>-0.326219</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "      <td>-0.188122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Nbr_of_Items  Total_Price  Date_diff  Nbr_trips_per_wk  \\\n",
       "0            0.086329    -0.236649   0.487672         -0.520909   \n",
       "1           -0.816953    -0.320357  -0.516810          2.902459   \n",
       "2            1.170267    -0.134987   0.822500         -1.376752   \n",
       "3           -0.455640    -0.307790  -0.181982          0.334933   \n",
       "4           -0.274984    -0.184135  -0.516810         -0.806190   \n",
       "\n",
       "   Nbr_items_per_wk  Total_Exp_wk_perc      hour  Bread_wk  Bread_exp_wk  \\\n",
       "0         -0.295981          -0.410729 -1.324821  2.398472      1.694186   \n",
       "1          0.983922          -0.972653  0.450253  0.566403     -0.473094   \n",
       "2         -1.350020           0.465925 -0.310493 -0.349632      0.511028   \n",
       "3          0.758057          -0.974993  0.450253  0.566403     -0.473094   \n",
       "4          0.231038          -0.460624  0.703836  0.566403     -0.473094   \n",
       "\n",
       "   Bread_wk_exp_perc  ...  Week_day_name_Monday  Week_day_name_Saturday  \\\n",
       "0           0.381548  ...             -0.449260               -0.483241   \n",
       "1          -0.494051  ...             -0.449260               -0.483241   \n",
       "2           3.008344  ...             -0.449260               -0.483241   \n",
       "3          -0.494051  ...             -0.449260               -0.483241   \n",
       "4          -0.494051  ...              2.225881               -0.483241   \n",
       "\n",
       "   Week_day_name_Sunday  Week_day_name_Thursday  Week_day_name_Tuesday  \\\n",
       "0             -0.326219               -0.393958               2.680951   \n",
       "1              3.065424               -0.393958              -0.373002   \n",
       "2             -0.326219               -0.393958              -0.373002   \n",
       "3              3.065424               -0.393958              -0.373002   \n",
       "4             -0.326219               -0.393958              -0.373002   \n",
       "\n",
       "   Week_day_name_Wednesday  Part_of_day_Afternoon  Part_of_day_Evening  \\\n",
       "0                -0.426978              -0.974374            -0.393958   \n",
       "1                -0.426978               1.026300            -0.393958   \n",
       "2                 2.342039               1.026300            -0.393958   \n",
       "3                -0.426978               1.026300            -0.393958   \n",
       "4                -0.426978               1.026300            -0.393958   \n",
       "\n",
       "   Part_of_day_Morning    target  \n",
       "0             1.445553 -0.294171  \n",
       "1            -0.691777  0.181543  \n",
       "2            -0.691777 -0.330668  \n",
       "3            -0.691777  0.582345  \n",
       "4            -0.691777 -0.188122  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c99595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract y_train and y_test from X_train and X_test\n",
    "y_train = X_train.target.values\n",
    "y_test = X_test.target.values\n",
    "\n",
    "# drop y_train and y_test from X_train and X_test\n",
    "X_train.drop(['target'], axis=1, inplace=True)\n",
    "X_test.drop(['target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c492d8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Nbr_of_Items</th>\n",
       "      <th>Total_Price</th>\n",
       "      <th>Date_diff</th>\n",
       "      <th>Nbr_trips_per_wk</th>\n",
       "      <th>Nbr_items_per_wk</th>\n",
       "      <th>Total_Exp_wk_perc</th>\n",
       "      <th>hour</th>\n",
       "      <th>Bread_wk</th>\n",
       "      <th>Bread_exp_wk</th>\n",
       "      <th>Bread_wk_exp_perc</th>\n",
       "      <th>...</th>\n",
       "      <th>Week_day_name_Friday</th>\n",
       "      <th>Week_day_name_Monday</th>\n",
       "      <th>Week_day_name_Saturday</th>\n",
       "      <th>Week_day_name_Sunday</th>\n",
       "      <th>Week_day_name_Thursday</th>\n",
       "      <th>Week_day_name_Tuesday</th>\n",
       "      <th>Week_day_name_Wednesday</th>\n",
       "      <th>Part_of_day_Afternoon</th>\n",
       "      <th>Part_of_day_Evening</th>\n",
       "      <th>Part_of_day_Morning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.086329</td>\n",
       "      <td>-0.236649</td>\n",
       "      <td>0.487672</td>\n",
       "      <td>-0.520909</td>\n",
       "      <td>-0.295981</td>\n",
       "      <td>-0.410729</td>\n",
       "      <td>-1.324821</td>\n",
       "      <td>2.398472</td>\n",
       "      <td>1.694186</td>\n",
       "      <td>0.381548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39654</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>-0.326219</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>2.680951</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>-0.974374</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>1.445553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.816953</td>\n",
       "      <td>-0.320357</td>\n",
       "      <td>-0.516810</td>\n",
       "      <td>2.902459</td>\n",
       "      <td>0.983922</td>\n",
       "      <td>-0.972653</td>\n",
       "      <td>0.450253</td>\n",
       "      <td>0.566403</td>\n",
       "      <td>-0.473094</td>\n",
       "      <td>-0.494051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39654</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>3.065424</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.170267</td>\n",
       "      <td>-0.134987</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>-1.376752</td>\n",
       "      <td>-1.350020</td>\n",
       "      <td>0.465925</td>\n",
       "      <td>-0.310493</td>\n",
       "      <td>-0.349632</td>\n",
       "      <td>0.511028</td>\n",
       "      <td>3.008344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39654</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>-0.326219</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>2.342039</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.455640</td>\n",
       "      <td>-0.307790</td>\n",
       "      <td>-0.181982</td>\n",
       "      <td>0.334933</td>\n",
       "      <td>0.758057</td>\n",
       "      <td>-0.974993</td>\n",
       "      <td>0.450253</td>\n",
       "      <td>0.566403</td>\n",
       "      <td>-0.473094</td>\n",
       "      <td>-0.494051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39654</td>\n",
       "      <td>-0.449260</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>3.065424</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.274984</td>\n",
       "      <td>-0.184135</td>\n",
       "      <td>-0.516810</td>\n",
       "      <td>-0.806190</td>\n",
       "      <td>0.231038</td>\n",
       "      <td>-0.460624</td>\n",
       "      <td>0.703836</td>\n",
       "      <td>0.566403</td>\n",
       "      <td>-0.473094</td>\n",
       "      <td>-0.494051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39654</td>\n",
       "      <td>2.225881</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>-0.326219</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.373002</td>\n",
       "      <td>-0.426978</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>-0.393958</td>\n",
       "      <td>-0.691777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Nbr_of_Items  Total_Price  Date_diff  Nbr_trips_per_wk  \\\n",
       "0            0.086329    -0.236649   0.487672         -0.520909   \n",
       "1           -0.816953    -0.320357  -0.516810          2.902459   \n",
       "2            1.170267    -0.134987   0.822500         -1.376752   \n",
       "3           -0.455640    -0.307790  -0.181982          0.334933   \n",
       "4           -0.274984    -0.184135  -0.516810         -0.806190   \n",
       "\n",
       "   Nbr_items_per_wk  Total_Exp_wk_perc      hour  Bread_wk  Bread_exp_wk  \\\n",
       "0         -0.295981          -0.410729 -1.324821  2.398472      1.694186   \n",
       "1          0.983922          -0.972653  0.450253  0.566403     -0.473094   \n",
       "2         -1.350020           0.465925 -0.310493 -0.349632      0.511028   \n",
       "3          0.758057          -0.974993  0.450253  0.566403     -0.473094   \n",
       "4          0.231038          -0.460624  0.703836  0.566403     -0.473094   \n",
       "\n",
       "   Bread_wk_exp_perc  ...  Week_day_name_Friday  Week_day_name_Monday  \\\n",
       "0           0.381548  ...              -0.39654             -0.449260   \n",
       "1          -0.494051  ...              -0.39654             -0.449260   \n",
       "2           3.008344  ...              -0.39654             -0.449260   \n",
       "3          -0.494051  ...              -0.39654             -0.449260   \n",
       "4          -0.494051  ...              -0.39654              2.225881   \n",
       "\n",
       "   Week_day_name_Saturday  Week_day_name_Sunday  Week_day_name_Thursday  \\\n",
       "0               -0.483241             -0.326219               -0.393958   \n",
       "1               -0.483241              3.065424               -0.393958   \n",
       "2               -0.483241             -0.326219               -0.393958   \n",
       "3               -0.483241              3.065424               -0.393958   \n",
       "4               -0.483241             -0.326219               -0.393958   \n",
       "\n",
       "   Week_day_name_Tuesday  Week_day_name_Wednesday  Part_of_day_Afternoon  \\\n",
       "0               2.680951                -0.426978              -0.974374   \n",
       "1              -0.373002                -0.426978               1.026300   \n",
       "2              -0.373002                 2.342039               1.026300   \n",
       "3              -0.373002                -0.426978               1.026300   \n",
       "4              -0.373002                -0.426978               1.026300   \n",
       "\n",
       "   Part_of_day_Evening  Part_of_day_Morning  \n",
       "0            -0.393958             1.445553  \n",
       "1            -0.393958            -0.691777  \n",
       "2            -0.393958            -0.691777  \n",
       "3            -0.393958            -0.691777  \n",
       "4            -0.393958            -0.691777  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e237c14",
   "metadata": {},
   "source": [
    "<h1 style=\"color: green;\">Hyperparameter tuning with GridSearchCV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c4ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['AdaBoost','Catboost','LightGBM','GradientBoosting','RandomForest','XGBoost']\n",
    "\n",
    "models_list = {\n",
    "    'AdaBoost': adb_r(),\n",
    "    'Catboost': catb_r(),\n",
    "    'LightGBM': lgbm_r(),\n",
    "    'GradientBoosting': gb_r(),\n",
    "    'RandomForest': rf_r(),\n",
    "    'XGBoost':xgb_r()\n",
    "}\n",
    "\n",
    "param_list = {\n",
    "    'AdaBoost': {\n",
    "                'n_estimators': [100, 300, 500, 800, 1000, 1500, 5000, 10000],\n",
    "                'learning_rate': [0.01, 0.03, 0.06, 0.08, 0.1, 0.15],\n",
    "                'loss': ['linear','square'],\n",
    "                'random_state': [44]\n",
    "    },\n",
    "    \n",
    "    'Catboost': {\n",
    "                'n_estimators': [100, 300, 500, 800, 1000, 1500, 5000, 10000],                \n",
    "                'learning_rate': [0.01, 0.03, 0.06, 0.08, 0.1, 0.15],\n",
    "                'depth': [4, 6, 8],\n",
    "                'verbose': [False],\n",
    "                'random_seed': [44]\n",
    "    },\n",
    "    \n",
    "    'LightGBM':{\n",
    "                'n_estimators': [100, 300, 500, 800, 1000, 1500, 5000, 10000],\n",
    "                'learning_rate': [0.01, 0.03, 0.06, 0.08, 0.1, 0.15],\n",
    "                'max_depth': [4, 6, 8, 10],\n",
    "    },\n",
    "    \n",
    "    'GradientBoosting': {                \n",
    "                'n_estimators': [100, 300, 500, 800, 1000, 1500, 5000, 10000],\n",
    "                'learning_rate': [0.01, 0.03, 0.06, 0.08, 0.1, 0.15],\n",
    "                'max_depth': [6, 8, 10],\n",
    "                'loss': ['squared_error','huber'],\n",
    "                'random_state': [44]\n",
    "    },\n",
    "    \n",
    "    'RandomForest': {\n",
    "                'n_estimators': [100, 300, 500, 800, 1000, 1500, 5000, 10000],\n",
    "                'max_depth': [6, 8, 10, 12],\n",
    "                'min_samples_split': [1, 3, 4, 6],\n",
    "                'random_state': [44]\n",
    "    },\n",
    "\n",
    "    'XGBoost':{                \n",
    "                'n_estimators': [100, 300, 500, 800, 1000, 1500, 5000, 10000],\n",
    "                'learning_rate': [0.01, 0.03, 0.06, 0.08, 0.1, 0.15],\n",
    "                'min_child_weight':[4,6,8],\n",
    "                'max_depth':[4,6,8],\n",
    "                'gamma':[0, 1],\n",
    "                'random_state':[4]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269f08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch_run(keys, param_list, models_list, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Scoring metric\n",
    "    # defining the scoring parameter to be passed into GridSearchCV\n",
    "    # 'neg_mean_squared_error', metrics.mean_squared_error is used here\n",
    "    # make_scorer and set greater_is_better to false to make sure \n",
    "    # GridSearchCV optimizes the hyperparameters correctly\n",
    "    scoring_metrics = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "    # Alternative\n",
    "    # scoring_metrics = \"neg_mean_squared_error\"\n",
    "\n",
    "    key_model_params = []\n",
    "    for key in keys:\n",
    "        string = []\n",
    "        string.append(key)\n",
    "        string.append(param_list[key])\n",
    "\n",
    "        gs = GridSearchCV(models_list[key],\n",
    "                          param_grid=param_list[key],\n",
    "                          cv=5, \n",
    "                          verbose=True, \n",
    "                          n_jobs=-1,\n",
    "                          scoring=scoring_metrics\n",
    "                         )\n",
    "\n",
    "        #gs.fit(X_train,y_train)\n",
    "        gs.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "        y_train_pred = gs.predict(X_train)\n",
    "        y_test_pred = gs.predict(X_test)\n",
    "\n",
    "        string.append(gs.best_params_)\n",
    "        string.append(-gs.best_score_)\n",
    "        string.append(np.sqrt(-gs.best_score_))\n",
    "\n",
    "        string.append(explained_variance_score(y_train,y_train_pred))\n",
    "        string.append(r2_score(y_train,y_train_pred))\n",
    "\n",
    "        string.append(-gs.score(X_test,y_test))\n",
    "        string.append(np.sqrt(-gs.score(X_test,y_test)))\n",
    "\n",
    "        string.append(explained_variance_score(y_test,y_test_pred))\n",
    "        string.append(r2_score(y_test,y_test_pred))\n",
    "        key_model_params.append(string)\n",
    "\n",
    "\n",
    "    return key_model_params\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a227e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    }
   ],
   "source": [
    "gridSearch_Output = gridSearch_run(keys, param_list, models_list, X_train, y_train, X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "496467e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Param_list_in</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>Explained_var_train</th>\n",
       "      <th>R_squared_train</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>Explained_var_test</th>\n",
       "      <th>R_squared_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'n_estimators': [100, 300, 500, 800, 1000, 15...</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'huber', 'max_...</td>\n",
       "      <td>0.026284</td>\n",
       "      <td>0.162122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.148443</td>\n",
       "      <td>0.982923</td>\n",
       "      <td>0.982651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'n_estimators': [100, 300, 500, 800, 1000, 15...</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'square', 'n_e...</td>\n",
       "      <td>0.073113</td>\n",
       "      <td>0.270395</td>\n",
       "      <td>0.951176</td>\n",
       "      <td>0.944947</td>\n",
       "      <td>0.058940</td>\n",
       "      <td>0.242775</td>\n",
       "      <td>0.957805</td>\n",
       "      <td>0.953596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>{'n_estimators': [100, 300, 500, 800, 1000, 15...</td>\n",
       "      <td>{'depth': 4, 'learning_rate': 0.06, 'n_estimat...</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.209948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.346845</td>\n",
       "      <td>0.906235</td>\n",
       "      <td>0.905286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'n_estimators': [100, 300, 500, 800, 1000, 15...</td>\n",
       "      <td>{'gamma': 0, 'learning_rate': 0.1, 'max_depth'...</td>\n",
       "      <td>0.063283</td>\n",
       "      <td>0.251560</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.129185</td>\n",
       "      <td>0.359423</td>\n",
       "      <td>0.900148</td>\n",
       "      <td>0.898292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'n_estimators': [100, 300, 500, 800, 1000, 15...</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 1, 'n_e...</td>\n",
       "      <td>0.182135</td>\n",
       "      <td>0.426773</td>\n",
       "      <td>0.972769</td>\n",
       "      <td>0.972756</td>\n",
       "      <td>0.231213</td>\n",
       "      <td>0.480846</td>\n",
       "      <td>0.818367</td>\n",
       "      <td>0.817964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>{'n_estimators': [100, 300, 500, 800, 1000, 15...</td>\n",
       "      <td>{'learning_rate': 0.06, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.117028</td>\n",
       "      <td>0.342093</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.341380</td>\n",
       "      <td>0.584277</td>\n",
       "      <td>0.732933</td>\n",
       "      <td>0.731229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model                                      Param_list_in  \\\n",
       "3  GradientBoosting  {'n_estimators': [100, 300, 500, 800, 1000, 15...   \n",
       "0          AdaBoost  {'n_estimators': [100, 300, 500, 800, 1000, 15...   \n",
       "1          Catboost  {'n_estimators': [100, 300, 500, 800, 1000, 15...   \n",
       "5           XGBoost  {'n_estimators': [100, 300, 500, 800, 1000, 15...   \n",
       "4      RandomForest  {'n_estimators': [100, 300, 500, 800, 1000, 15...   \n",
       "2          LightGBM  {'n_estimators': [100, 300, 500, 800, 1000, 15...   \n",
       "\n",
       "                                         best_params  train_mse  train_rmse  \\\n",
       "3  {'learning_rate': 0.01, 'loss': 'huber', 'max_...   0.026284    0.162122   \n",
       "0  {'learning_rate': 0.03, 'loss': 'square', 'n_e...   0.073113    0.270395   \n",
       "1  {'depth': 4, 'learning_rate': 0.06, 'n_estimat...   0.044078    0.209948   \n",
       "5  {'gamma': 0, 'learning_rate': 0.1, 'max_depth'...   0.063283    0.251560   \n",
       "4  {'max_depth': 12, 'min_samples_split': 1, 'n_e...   0.182135    0.426773   \n",
       "2  {'learning_rate': 0.06, 'max_depth': 4, 'n_est...   0.117028    0.342093   \n",
       "\n",
       "   Explained_var_train  R_squared_train  test_mse  test_rmse  \\\n",
       "3             1.000000         1.000000  0.022035   0.148443   \n",
       "0             0.951176         0.944947  0.058940   0.242775   \n",
       "1             1.000000         1.000000  0.120301   0.346845   \n",
       "5             0.999991         0.999991  0.129185   0.359423   \n",
       "4             0.972769         0.972756  0.231213   0.480846   \n",
       "2             0.999983         0.999983  0.341380   0.584277   \n",
       "\n",
       "   Explained_var_test  R_squared_test  \n",
       "3            0.982923        0.982651  \n",
       "0            0.957805        0.953596  \n",
       "1            0.906235        0.905286  \n",
       "5            0.900148        0.898292  \n",
       "4            0.818367        0.817964  \n",
       "2            0.732933        0.731229  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = pd.DataFrame(gridSearch_Output, columns =['Model',\n",
    "                                                            'Param_list_in',\n",
    "                                                            'best_params',\n",
    "                                                            'train_mse',\n",
    "                                                            'train_rmse',\n",
    "                                                            'Explained_var_train',\n",
    "                                                            'R_squared_train',\n",
    "                                                            'test_mse',\n",
    "                                                            'test_rmse',\n",
    "                                                            'Explained_var_test',\n",
    "                                                            'R_squared_test'])\n",
    "model_output.sort_values(by='test_mse', ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f4935",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29fda846",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">Retrieving the best parameters for the models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb938c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'learning_rate': 0.01,\n",
       "  'loss': 'huber',\n",
       "  'max_depth': 8,\n",
       "  'n_estimators': 10000,\n",
       "  'random_state': 44}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best params for GradientBoosting\n",
    "x = model_output[['Model','best_params']].query(\"Model=='GradientBoosting'\")\n",
    "gbr_params = x.best_params.to_list()\n",
    "gbr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba4aa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'learning_rate': 0.03,\n",
       "  'loss': 'square',\n",
       "  'n_estimators': 5000,\n",
       "  'random_state': 44}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best params for AdaBoost\n",
    "x = model_output[['Model','best_params']].query(\"Model=='AdaBoost'\")\n",
    "adb_params = x.best_params.to_list()\n",
    "adb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90bfc2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'depth': 4,\n",
       "  'learning_rate': 0.06,\n",
       "  'n_estimators': 10000,\n",
       "  'random_seed': 44,\n",
       "  'verbose': False}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best params for Catboost\n",
    "x = model_output[['Model','best_params']].query(\"Model=='Catboost'\")\n",
    "catb_params = x.best_params.to_list()\n",
    "catb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0e0f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gamma': 0,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 4,\n",
       "  'min_child_weight': 8,\n",
       "  'n_estimators': 1500,\n",
       "  'random_state': 4}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best params for XGBoost\n",
    "x = model_output[['Model','best_params']].query(\"Model=='XGBoost'\")\n",
    "xgb_params = x.best_params.to_list()\n",
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56edaff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 12,\n",
       "  'min_samples_split': 1,\n",
       "  'n_estimators': 1500,\n",
       "  'random_state': 44}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best params for RandomForest\n",
    "x = model_output[['Model','best_params']].query(\"Model=='RandomForest'\")\n",
    "rfr_params = x.best_params.to_list()\n",
    "rfr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb13d03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'learning_rate': 0.06, 'max_depth': 4, 'n_estimators': 5000}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the best params for LightGBM\n",
    "x = model_output[['Model','best_params']].query(\"Model=='LightGBM'\")\n",
    "lgbm_params = x.best_params.to_list()\n",
    "lgbm_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c205b9c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">Cross validating with cross_val_score</h3>\n",
    "<p>\n",
    "Cross-validation provides information about how well a model generalizes i.e. how well the model can predict<br>\n",
    "using previously unseen data. This is an indicator of the model's would be performance once deployed.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e9421",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">Function to return rmse via cross validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36600482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE function\n",
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model,X,y, scoring=\"neg_mean_squared_error\",cv=10))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f2798",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24c1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['AdaBoost','Catboost','LightGBM','GradientBoosting',\n",
    "          'RandomForest','XGBoost']\n",
    "\n",
    "\n",
    "models_list = {\n",
    "    'AdaBoost': adb_r(\n",
    "            n_estimators = 5000,\n",
    "            learning_rate = 0.03,\n",
    "            loss = 'square',\n",
    "            random_state = 44      \n",
    "    ),\n",
    "    'Catboost': catb_r(\n",
    "            learning_rate = 0.06,\n",
    "            n_estimators = 10000,\n",
    "            depth = 4,            \n",
    "            random_seed = 44,\n",
    "            verbose = False\n",
    "    ),\n",
    "    \n",
    "    'LightGBM': lgbm_r(\n",
    "            n_estimators = 5000,\n",
    "            learning_rate = 0.06,\n",
    "            max_depth = 4\n",
    "    ),\n",
    "    \n",
    "    'GradientBoosting': gb_r(\n",
    "            n_estimators = 10000,\n",
    "            learning_rate = 0.01,\n",
    "            max_depth = 8,\n",
    "            loss = 'huber',\n",
    "            random_state = 44       \n",
    "    ),\n",
    "    \n",
    "    'RandomForest': rf_r(\n",
    "            n_estimators = 1500,\n",
    "            max_depth = 12,\n",
    "            min_samples_split = 1,\n",
    "            random_state = 44     \n",
    "    ),\n",
    "    'XGBoost':xgb_r(\n",
    "            n_estimators = 1500,\n",
    "            learning_rate = 0.1,\n",
    "            max_depth = 4,\n",
    "            min_child_weight = 8,\n",
    "            gamma = 0,\n",
    "            random_state = 4\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06cb538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_model_params = []\n",
    "\n",
    "for key in keys:\n",
    "    string = []\n",
    "    \n",
    "    rmse = rmse_cv(models_list[key],X_train, y_train)\n",
    "    \n",
    "    string.append(key)\n",
    "    string.append(rmse.mean())\n",
    "    \n",
    "    key_model_params.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0cc410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>rmse_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.132949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.195851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.228794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.267038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.295754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.363437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   rmse_cv\n",
       "3  GradientBoosting  0.132949\n",
       "1          Catboost  0.195851\n",
       "5           XGBoost  0.228794\n",
       "0          AdaBoost  0.267038\n",
       "2          LightGBM  0.295754\n",
       "4      RandomForest  0.363437"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cv_10_regressor = pd.DataFrame(key_model_params, \n",
    "                                columns =['Model',\n",
    "                                          'rmse_cv'])\n",
    "\n",
    "Cv_10_regressor.sort_values(by=['rmse_cv'], \n",
    "                                  ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52348e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48b5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdba8134",
   "metadata": {},
   "source": [
    "<P>\n",
    "On the basis of test rmse with cross validation score, the top 4 models are:\n",
    "<ol>\n",
    "    <li>GradientBoosting</li>\n",
    "    <li>AdaBoost</li>\n",
    "    <li>CatBoost</li>\n",
    "    <li>XGBoost</li>\n",
    "</ol>    \n",
    "<b>Surprisingly, XGBoost is not the best performing model.</b><br><br>\n",
    "Below the best params for the top 4 models judging by test rmse will be used to compare the best model with an<br> ensemble voting regressor before a final decision is made as to which model we will go ahead with.<br>\n",
    "</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac69433",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">Ensemble VotingRegressor</h3>\n",
    "<p>\n",
    "Ensembles are used to achieve better predictive performance than a single predictive model. This operates on the <br>same principle as combining weak learners to collectively make a consistent decision, bagging/bootstrapping.<br>Thus the weakness of any one model is overcome by the crowd.\n",
    "</p>\n",
    "<p>\n",
    "Below we group the four models, an ensemble, to see if they outperform the best amongst them, GradientBoosting on it's own.<br>Note, GradientBoosting GridSearch test mse is already low, the voting regressor must exhibit a significant improvement on this for it to be<br> considered worthy.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df2899",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = vot_r([\n",
    "              ('GradientBoosting',gb_r(\n",
    "                learning_rate = 0.01,\n",
    "                loss= 'huber',\n",
    "                max_depth = 8,\n",
    "                n_estimators = 5000,\n",
    "                random_state = 44\n",
    "                )),\n",
    "\n",
    "              ('AdaBoost',adb_r(\n",
    "                n_estimators = 800,\n",
    "                learning_rate = 0.06,\n",
    "                loss = 'square',\n",
    "                random_state = 44\n",
    "                )),\n",
    "              ('Catboost',catb_r(\n",
    "                n_estimators = 10000,\n",
    "                learning_rate =  0.01,    \n",
    "                depth = 4,\n",
    "                verbose = False,\n",
    "                random_seed = 44,\n",
    "                )),\n",
    "\n",
    "              ('XGBoost',xgb_r(\n",
    "                n_estimators = 5000,\n",
    "                learning_rate= 0.08,    \n",
    "                gamma = 0,\n",
    "                max_depth = 4,\n",
    "                min_child_weight= 8,\n",
    "                random_state= 4\n",
    "                ))\n",
    "            ])\n",
    "\n",
    "\n",
    "print(\"Number of models in the regressor: {0}\".format(len(voting.estimators)))\n",
    "\n",
    "# Fitting the models on X_train y_train\n",
    "voting.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting regressor without Gradient Boosting to see the absence effect\n",
    "voting1 = vot_r([\n",
    "              ('AdaBoost',adb_r(\n",
    "                n_estimators = 800,\n",
    "                learning_rate = 0.06,\n",
    "                loss = 'square',\n",
    "                random_state = 44\n",
    "                )),\n",
    "              ('Catboost',catb_r(\n",
    "                n_estimators = 10000,\n",
    "                learning_rate =  0.01,    \n",
    "                depth = 4,\n",
    "                verbose = False,\n",
    "                random_seed = 44,\n",
    "                )),\n",
    "\n",
    "              ('XGBoost',xgb_r(\n",
    "                n_estimators = 5000,\n",
    "                learning_rate= 0.08,    \n",
    "                gamma = 0,\n",
    "                max_depth = 4,\n",
    "                min_child_weight= 8,\n",
    "                random_state= 4\n",
    "                ))\n",
    "            ])\n",
    "\n",
    "\n",
    "print(\"Number of models in the regressor: {0}\".format(len(voting.estimators)))\n",
    "\n",
    "# Fitting the models on X_train y_train\n",
    "voting1.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1d775",
   "metadata": {},
   "source": [
    "<h5 style=\"color: green;\">Cross validating the voting regressors</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41016643",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_rmse = rmse_cv(voting,X_train,y_train)\n",
    "voting_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57131c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting without GradientBoosting cross validation\n",
    "voting1_rmse = rmse_cv(voting1,X_train,y_train)\n",
    "voting1_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting1_rmse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf922bb0",
   "metadata": {},
   "source": [
    "<b>\n",
    "Above, it is clear that the exclusion of the GradientBoosting regressor increases the errors worsening the voting <br>regressor performance, albeit marginal.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef5d48",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">GradientBoosting regressor best model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f141e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_reg = gb_r(\n",
    "    learning_rate = 0.01,\n",
    "    loss= 'huber',\n",
    "    max_depth = 8,\n",
    "    n_estimators = 5000,\n",
    "    random_state = 44\n",
    "    )\n",
    "\n",
    "GB_reg.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d78cf0",
   "metadata": {},
   "source": [
    "<h5 style=\"color: green;\">Cross validating the GradientBoosting regressor model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3689c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_reg_rmse = rmse_cv(GB_reg,X_train,y_train)\n",
    "GB_reg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_reg_rmse.mean(), voting_rmse.mean(),voting1_rmse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4502c0",
   "metadata": {},
   "source": [
    "<p>\n",
    "The cross validation output indicates that there is a difference between voting regressor and the <br> GradientBoosting regressor. It's the fact that the GradientBoosting model is powerful enough to be highly<br> predictive on it's own that the voting regressor can be discarded.<br><br>Further, there maybe efficiency improvement in deploying one model instead of an ensemble.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d4b5e",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">Working with the best model, GradientBoosting regressor</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict y_train\n",
    "train_y_pred = GB_reg.predict(X_train)\n",
    "\n",
    "# Retrieve the training rmse,r2_score\n",
    "print(\"Training RMSE: {}\".format(np.sqrt(mean_squared_error(y_train,train_y_pred))))\n",
    "print(\"Training R-squared: {}\\n\".format(r2_score(y_train,train_y_pred)))\n",
    "\n",
    "\n",
    "test_y_pred = GB_reg.predict(X_test)\n",
    "# Retrieve the test rmse,r2_score\n",
    "print(\"\\nTest RMSE: {}\".format(np.sqrt(mean_squared_error(y_test,test_y_pred))))\n",
    "print(\"Test R-squared: {}\".format(r2_score(y_test,test_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fc4b7",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">Feature importance for GradientBoosting regressor</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b57f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_imp = pd.Series(GB_reg.feature_importances_, \n",
    "                    index=X_train.columns)\n",
    "\n",
    "# plotting importance\n",
    "# figure background\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('#212121')\n",
    "fig.patch.set_alpha(0.95)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.patch.set_facecolor('#212121')\n",
    "ax.patch.set_alpha(1.0)\n",
    "ax.yaxis.label.set_color('lime')\n",
    "ax.xaxis.label.set_color('lime')\n",
    "ax.title.set_color('lime')\n",
    "ax.tick_params(colors='lime', which='both')\n",
    "\n",
    "\n",
    "GBR_imp.nlargest(19).sort_values().plot(ax=ax,\n",
    "                                        kind='barh', \n",
    "                                        color='red',\n",
    "                                        title='GradientBoosting feature importance\\nImpurity based')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7e412",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green;\">Exporting the best model from GridSearchCV</h3>\n",
    "This is done for extracting feature importance list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24712b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(GB_reg, \"../8. Models/Regressor_models/GB_reg_gridsearch_best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b6ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
